{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1220d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "_DEF_RE = re.compile(r\"^def\\s+([A-Za-z_]\\w*)\\s*\\((.*?)\\)\\s*(?:->\\s*([^:]+))?:\\s*$\", re.M,)\n",
    "\n",
    "_PARAM_NAME_RE = re.compile(r\"^\\s*([A-Za-z_]\\w*)\\s*(?::|=|$)\")\n",
    "\n",
    "\n",
    "def extract_def_header(prompt: str) -> Tuple[str, str, Optional[str], int, int]:\n",
    "    \"\"\"\n",
    "    Locate the first function definition line: def name(params)\n",
    "    \"\"\"\n",
    "    m = _DEF_RE.search(prompt)\n",
    "    if not m:\n",
    "        raise ValueError(\"No function definition line found in prompt.\")\n",
    "    func_name = m.group(1)\n",
    "    params_str = m.group(2)\n",
    "    ret = m.group(3).strip() if m.group(3) else None\n",
    "    return func_name, params_str, ret, m.start(), m.end()\n",
    "\n",
    "\n",
    "def _split_params(params_str: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split parameters by commas while respecting nesting ([], (), {}).\n",
    "    Prevents breaking types like List[Tuple[int,int]] or default tuples.\n",
    "    \"\"\"\n",
    "    out, buf = [], []\n",
    "    depth = 0\n",
    "    for ch in params_str:\n",
    "        if ch in \"([{\":\n",
    "            depth += 1\n",
    "        elif ch in \")]}\":\n",
    "            depth = max(0, depth - 1)\n",
    "\n",
    "        if ch == \",\" and depth == 0:\n",
    "            token = \"\".join(buf).strip()\n",
    "            if token:\n",
    "                out.append(token)\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(ch)\n",
    "\n",
    "    tail = \"\".join(buf).strip()\n",
    "    if tail:\n",
    "        out.append(tail)\n",
    "    return out\n",
    "\n",
    "\n",
    "def parse_param_name(token: str) -> Optional[str]:\n",
    "    #Extract the parameter name from a param token, ignoring '*' and '/'.\n",
    "    token = token.strip()\n",
    "    if token in {\"*\", \"/\"}:\n",
    "        return None\n",
    "    m = _PARAM_NAME_RE.match(token)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "def build_param_rename_map(prompt: str, style: str = \"arg\") -> Dict[str, str]:\n",
    "    # Build a deterministic mapping old_param -> new_param.\n",
    "    _, params_str, _, _, _ = extract_def_header(prompt)\n",
    "    tokens = _split_params(params_str)\n",
    "    names = [parse_param_name(t) for t in tokens]\n",
    "    names = [n for n in names if n is not None]\n",
    "\n",
    "    mapping: Dict[str, str] = {}\n",
    "    for i, old in enumerate(names):\n",
    "        new = f\"arg{i}\" if style == \"arg\" else f\"x{i}\"\n",
    "        mapping[old] = new\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def rename_parameters_in_def(prompt: str, mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Rename parameter names *only in the function signature*.\n",
    "    Keeps annotations and defaults intact.\n",
    "    \"\"\"\n",
    "    func_name, params_str, ret, start, end = extract_def_header(prompt)\n",
    "    tokens = _split_params(params_str)\n",
    "\n",
    "    new_tokens = []\n",
    "    for tok in tokens:\n",
    "        name = parse_param_name(tok)\n",
    "        if name and name in mapping:\n",
    "            tok = re.sub(rf\"^\\s*{re.escape(name)}\\b\", mapping[name], tok)\n",
    "        new_tokens.append(tok)\n",
    "\n",
    "    new_params_str = \", \".join(new_tokens)\n",
    "    new_header = f\"def {func_name}({new_params_str})\"\n",
    "    if ret is not None:\n",
    "        new_header += f\" -> {ret}\"\n",
    "    new_header += \":\"\n",
    "\n",
    "    return prompt[:start] + new_header + prompt[end:]\n",
    "\n",
    "\n",
    "# Docstring extraction & rewriting\n",
    "\n",
    "\n",
    "_DOC_RE = re.compile(r'(\\n[ \\t]*)(\"\"\"|\\'\\'\\')([\\s\\S]*?)(\\2)')\n",
    "\n",
    "def extract_first_docstring(prompt: str) -> Optional[Tuple[str, str, str, int, int]]:\n",
    "    m = _DOC_RE.search(prompt)\n",
    "    if not m:\n",
    "        return None\n",
    "    indent_prefix = m.group(1)         # e.g., \"\\n    \"\n",
    "    quote = m.group(2)                 # \"\"\" or '''\n",
    "    inner = m.group(3)                 # content inside\n",
    "    start = m.start(2)\n",
    "    end = m.end(4)\n",
    "    return indent_prefix, quote, inner, start, end\n",
    "\n",
    "\n",
    "def rename_identifiers_in_docstring(prompt: str, mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Low-obf: replace parameter mentions inside docstring (word-boundary).\n",
    "    Keeps doctests intact.\n",
    "    \"\"\"\n",
    "    doc = extract_first_docstring(prompt)\n",
    "    if not doc:\n",
    "        return prompt\n",
    "    indent_prefix, quote, inner, start, end = doc\n",
    "\n",
    "    new_inner = inner\n",
    "    for old, new in mapping.items():\n",
    "        new_inner = re.sub(rf\"\\b{re.escape(old)}\\b\", new, new_inner)\n",
    "\n",
    "    new_block = f\"{quote}{new_inner}{quote}\"\n",
    "    return prompt[:start] + new_block + prompt[end:]\n",
    "\n",
    "\n",
    "# High-obf docstring sanitizer: keep task contract, drop fingerprints\n",
    "\n",
    "_DOCTEST_LINE_RE = re.compile(r\"^\\s*>>>\\s*\")\n",
    "_EXAMPLE_LIKE_RE = re.compile(\n",
    "    r\"^\\s*(e\\.g\\.|eg\\.|example:|examples:|for example|E\\.g\\.|Eg\\.)\", re.IGNORECASE\n",
    ")\n",
    "\n",
    "def strip_doctest_blocks(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove doctest input lines ('>>> ...') and the immediate following output lines.\n",
    "    Heuristic: after a >>> line, drop subsequent non-empty lines until blank or next >>>.\n",
    "    \"\"\"\n",
    "    lines = text.splitlines()\n",
    "    out = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        if _DOCTEST_LINE_RE.match(line):\n",
    "            i += 1\n",
    "            # skip expected outputs\n",
    "            while i < len(lines):\n",
    "                nxt = lines[i]\n",
    "                if _DOCTEST_LINE_RE.match(nxt):\n",
    "                    break\n",
    "                if nxt.strip() == \"\":\n",
    "                    i += 1\n",
    "                    break\n",
    "                i += 1\n",
    "            continue\n",
    "        out.append(line)\n",
    "        i += 1\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "\n",
    "def sanitize_docstring_keep_contract(inner: str, mapping: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    High-obf: keep enough semantics to solve, remove solution fingerprints:\n",
    "      - remove doctests\n",
    "      - remove explicit example lines (E.g., Example:)\n",
    "      - remove formula-heavy lines (simple heuristic)\n",
    "      - rename parameter mentions to match renamed signature\n",
    "      - soften some highly-specific phrasing (lightweight synonym rules)\n",
    "      - compress to a short contract-style docstring (1-4 lines)\n",
    "    \"\"\"\n",
    "    # drop doctest blocks\n",
    "    text = strip_doctest_blocks(inner)\n",
    "\n",
    "    # drop obvious example lines\n",
    "    lines = text.splitlines()\n",
    "    kept: List[str] = []\n",
    "    for ln in lines:\n",
    "        if _EXAMPLE_LIKE_RE.match(ln.strip()):\n",
    "            continue\n",
    "        # Drop lines that look like \"MAD = average | x - x_mean |\" etc.\n",
    "        # Heuristic: has '=' and at least one math-ish symbol.\n",
    "        if \"=\" in ln and any(sym in ln for sym in [\"|\", \"*\", \"+\", \"-\", \"/\", \"^\"]):\n",
    "            continue\n",
    "        kept.append(ln)\n",
    "\n",
    "    text = \"\\n\".join(kept)\n",
    "\n",
    "    # rename parameter mentions\n",
    "    for old, new in mapping.items():\n",
    "        text = re.sub(rf\"\\b{re.escape(old)}\\b\", new, text)\n",
    "\n",
    "    # light synonym softening (keeps solvable, reduces \"canonical fingerprint\")\n",
    "    # Keep these conservative; we do NOT want to destroy task meaning.\n",
    "    synonym_rules = [\n",
    "        (r\"\\bbank account\\b\", \"running total\"),\n",
    "        (r\"\\bbalance\\b\", \"cumulative value\"),\n",
    "        (r\"\\bMean Absolute Deviation\\b\", \"a dispersion measure\"),\n",
    "        (r\"\\bMAD\\b\", \"dispersion value\"),\n",
    "        (r\"\\bnested parentheses\\b\", \"parenthesis structure\"),\n",
    "        (r\"\\bdeepest level of nesting\\b\", \"maximum nesting depth\"),\n",
    "        (r\"\\bdecomposed\\b\", \"split\"),\n",
    "        (r\"\\binteger part\\b\", \"whole-number part\"),\n",
    "        (r\"\\bdecimal part\\b\", \"fractional part\"),\n",
    "    ]\n",
    "    for pat, repl in synonym_rules:\n",
    "        text = re.sub(pat, repl, text, flags=re.IGNORECASE)\n",
    "\n",
    "    # normalize whitespace\n",
    "    text = \"\\n\".join([ln.rstrip() for ln in text.splitlines()])\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "\n",
    "    # contract-style compression:\n",
    "    # Keep the first 1–3 non-empty sentences/lines that describe behavior.\n",
    "    # This preserves task solvability but removes verbose guidance.\n",
    "    # Strategy:\n",
    "    #   - prefer non-empty lines\n",
    "    #   - stop after we have ~3 lines or ~300 chars\n",
    "    out_lines: List[str] = []\n",
    "    for ln in text.splitlines():\n",
    "        s = ln.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        out_lines.append(s)\n",
    "        if len(out_lines) >= 3:\n",
    "            break\n",
    "        if sum(len(x) for x in out_lines) >= 300:\n",
    "            break\n",
    "\n",
    "    if not out_lines:\n",
    "        out_lines = [\"Implement the function described by its signature.\"]\n",
    "\n",
    "    # Ensure ends with period-ish\n",
    "    compact = \" \".join(out_lines)\n",
    "    compact = re.sub(r\"\\s+\", \" \", compact).strip()\n",
    "    if compact and compact[-1] not in \".!?\":\n",
    "        compact += \".\"\n",
    "\n",
    "    return compact\n",
    "\n",
    "\n",
    "def replace_docstring_with_sanitized(prompt: str, sanitized_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replace the first docstring content with sanitized_text.\n",
    "    If docstring doesn't exist, insert it right after def line.\n",
    "    Preserves indentation.\n",
    "    \"\"\"\n",
    "    def_match = _DEF_RE.search(prompt)\n",
    "    if not def_match:\n",
    "        raise ValueError(\"No function definition line found in prompt.\")\n",
    "\n",
    "    # Infer indentation for function body\n",
    "    after_def = prompt[def_match.end():]\n",
    "    indent_match = re.search(r\"\\n([ \\t]+)\", after_def)\n",
    "    indent = indent_match.group(1) if indent_match else \"    \"\n",
    "\n",
    "    # Build sanitized docstring block\n",
    "    new_doc = (\n",
    "        indent + '\"\"\"\\n'\n",
    "        + indent + sanitized_text.strip() + \"\\n\"\n",
    "        + indent + '\"\"\"'\n",
    "    )\n",
    "\n",
    "    doc = extract_first_docstring(prompt)\n",
    "    if doc:\n",
    "        indent_prefix, quote, _, start, end = doc\n",
    "        # Keep existing indentation before opening quotes\n",
    "        existing_indent = indent_prefix.split(\"\\n\")[-1]\n",
    "\n",
    "        replacement = (\n",
    "            existing_indent + '\"\"\"\\n'\n",
    "            + existing_indent + sanitized_text.strip() + \"\\n\"\n",
    "            + existing_indent + '\"\"\"'\n",
    "        )\n",
    "\n",
    "        return prompt[:start] + replacement + prompt[end:]\n",
    "    else:\n",
    "        # Insert docstring right after def line\n",
    "        insert_at = def_match.end()\n",
    "        insertion = \"\\n\" + new_doc + \"\\n\"\n",
    "        return prompt[:insert_at] + insertion + prompt[insert_at:]\n",
    "\n",
    "\n",
    "# Formatting helpers + final low/high obfuscators\n",
    "\n",
    "def normalize_whitespace(prompt: str) -> str:\n",
    "    \"\"\"Remove trailing spaces and collapse 3+ blank lines to 2.\"\"\"\n",
    "    prompt = \"\\n\".join([ln.rstrip() for ln in prompt.splitlines()])\n",
    "    prompt = re.sub(r\"\\n{3,}\", \"\\n\\n\", prompt)\n",
    "    return prompt.strip() + \"\\n\"\n",
    "\n",
    "\n",
    "def low_obfuscate(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Low obfuscation:\n",
    "      - rename parameters in signature\n",
    "      - optionally update docstring parameter mentions\n",
    "      - keep doctests/examples\n",
    "    \"\"\"\n",
    "    mapping = build_param_rename_map(prompt, style=\"arg\")\n",
    "    out = rename_parameters_in_def(prompt, mapping)\n",
    "    out = rename_identifiers_in_docstring(out, mapping)\n",
    "    return normalize_whitespace(out)\n",
    "\n",
    "\n",
    "def high_obfuscate(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    High obfuscation:\n",
    "      - rename parameters in signature\n",
    "      - sanitize docstring:\n",
    "          * remove doctests/examples\n",
    "          * keep short contract text (solvable)\n",
    "          * soften named/fingerprint phrases lightly\n",
    "    \"\"\"\n",
    "    mapping = build_param_rename_map(prompt, style=\"arg\")\n",
    "    out = rename_parameters_in_def(prompt, mapping)\n",
    "\n",
    "    doc = extract_first_docstring(out)\n",
    "    if doc:\n",
    "        _, _, inner, _, _ = doc\n",
    "        sanitized = sanitize_docstring_keep_contract(inner, mapping)\n",
    "        out = replace_docstring_with_sanitized(out, sanitized)\n",
    "    else:\n",
    "        out = replace_docstring_with_sanitized(out, \"Implement the function described by its signature.\")\n",
    "\n",
    "    return normalize_whitespace(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70b32d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac07bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_20 = load_from_disk(\"./data/openai_humaneval/humaneval_test_20\")\n",
    "df_20 = ds_20.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7027272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks passed.\n"
     ]
    }
   ],
   "source": [
    "def sanity_check(prompt: str):\n",
    "    # must contain exactly one function def\n",
    "    assert prompt.count(\"def \") == 1, \"Unexpected number of function defs\"\n",
    "\n",
    "    # must end with colon after def\n",
    "    assert re.search(r\"def\\s+\\w+\\(.*\\)\\s*(->\\s*[^:]+)?:\", prompt), \"Bad def header\"\n",
    "\n",
    "    # no doctests in high obf\n",
    "    assert \">>>\" not in prompt, \"Doctest leaked into high obfuscation\"\n",
    "\n",
    "for idx, prompt in test_prompts.items():\n",
    "    sanity_check(high_obfuscate(prompt))\n",
    "\n",
    "print(\"Sanity checks passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca1a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "      <th>test</th>\n",
       "      <th>entry_point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>has_close_elements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>separate_paren_groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>truncate_number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>below_zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>mean_absolute_deviation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id  ...              entry_point\n",
       "0  HumanEval/0  ...       has_close_elements\n",
       "1  HumanEval/1  ...    separate_paren_groups\n",
       "2  HumanEval/2  ...          truncate_number\n",
       "3  HumanEval/3  ...               below_zero\n",
       "4  HumanEval/4  ...  mean_absolute_deviation\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cb0991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d8c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20 = df_20.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2131ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3160.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HF dataset: ./data/openai_humaneval/humaneval_test_20_with_obf2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_20[\"prompt_original\"] = df_20[\"prompt\"]\n",
    "df_20[\"prompt_low\"] = df_20[\"prompt\"].apply(low_obfuscate)\n",
    "df_20[\"prompt_high\"] = df_20[\"prompt\"].apply(high_obfuscate)\n",
    "\n",
    "ds_20_obf = Dataset.from_pandas(df_20, preserve_index=False)\n",
    "\n",
    "save_dir = \"./data/openai_humaneval/humaneval_test_20_with_obf\"\n",
    "ds_20_obf.save_to_disk(save_dir)\n",
    "\n",
    "print(\"Saved HF dataset:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c758f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_20_obf = load_from_disk(\"./data/openai_humaneval/humaneval_test_20_with_obf\")\n",
    "df_20 = ds_20_obf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5e2508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "      <th>test</th>\n",
       "      <th>entry_point</th>\n",
       "      <th>prompt_original</th>\n",
       "      <th>prompt_low</th>\n",
       "      <th>prompt_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>has_close_elements</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>separate_paren_groups</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>truncate_number</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>below_zero</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>mean_absolute_deviation</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id  ...                                        prompt_high\n",
       "0  HumanEval/0  ...  from typing import List\\n\\ndef has_close_eleme...\n",
       "1  HumanEval/1  ...  from typing import List\\n\\ndef separate_paren_...\n",
       "2  HumanEval/2  ...  def truncate_number(arg0: float) -> float:\\n  ...\n",
       "3  HumanEval/3  ...  from typing import List\\n\\ndef below_zero(arg0...\n",
       "4  HumanEval/4  ...  from typing import List\\n\\ndef mean_absolute_d...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17e4a568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_20.iloc[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0425f9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_20.iloc[0][\"prompt_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a20002e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_from_disk(\"./data/openai_humaneval/humaneval_test_20_with_obf\")\n",
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c140c52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "      <th>test</th>\n",
       "      <th>entry_point</th>\n",
       "      <th>prompt_original</th>\n",
       "      <th>prompt_low</th>\n",
       "      <th>prompt_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>has_close_elements</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>separate_paren_groups</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>truncate_number</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>below_zero</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>mean_absolute_deviation</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id  ...                                        prompt_high\n",
       "0  HumanEval/0  ...  from typing import List\\n\\ndef has_close_eleme...\n",
       "1  HumanEval/1  ...  from typing import List\\n\\ndef separate_paren_...\n",
       "2  HumanEval/2  ...  def truncate_number(arg0: float) -> float:\\n  ...\n",
       "3  HumanEval/3  ...  from typing import List\\n\\ndef below_zero(arg0...\n",
       "4  HumanEval/4  ...  from typing import List\\n\\ndef mean_absolute_d...\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16f059c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function-name invariants OK.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_func_name(prompt: str) -> str:\n",
    "    m = re.search(r\"^def\\s+([A-Za-z_]\\w*)\\s*\\(\", prompt, re.M)\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "for i in range(len(df_20)):\n",
    "    a = get_func_name(df.loc[i, \"prompt_original\"])\n",
    "    b = get_func_name(df.loc[i, \"prompt_low\"])\n",
    "    c = get_func_name(df.loc[i, \"prompt_high\"])\n",
    "    assert a == b == c, f\"Function name changed at row {i}: {a}, {b}, {c}\"\n",
    "\n",
    "print(\"Function-name invariants OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "474e2814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List, Tuple\n",
      "\n",
      "def sum_product(arg0: List[int]) -> Tuple[int, int]:\n",
      "        \"\"\"\n",
      "    For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list. Empty sum should be equal to 0 and empty product should be equal to 1.\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[8][\"prompt_high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e165d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List, Tuple\n",
      "\n",
      "def sum_product(arg0: List[int]) -> Tuple[int, int]:\n",
      "    \"\"\" For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n",
      "    Empty sum should be equal to 0 and empty product should be equal to 1.\n",
      "    >>> sum_product([])\n",
      "    (0, 1)\n",
      "    >>> sum_product([1, 2, 3, 4])\n",
      "    (10, 24)\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[8][\"prompt_low\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
