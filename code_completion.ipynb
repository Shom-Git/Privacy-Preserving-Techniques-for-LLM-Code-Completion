{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897b8681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/crp-custom-env/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7c9106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "      <th>test</th>\n",
       "      <th>entry_point</th>\n",
       "      <th>prompt_original</th>\n",
       "      <th>prompt_low</th>\n",
       "      <th>prompt_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>has_close_elements</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>separate_paren_groups</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>truncate_number</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>below_zero</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>mean_absolute_deviation</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id                                             prompt  \\\n",
       "0  HumanEval/0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  HumanEval/1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  HumanEval/2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  HumanEval/3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  HumanEval/4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                  canonical_solution  \\\n",
       "0      for idx, elem in enumerate(numbers):\\n    ...   \n",
       "1      result = []\\n    current_string = []\\n    ...   \n",
       "2                              return number % 1.0\\n   \n",
       "3      balance = 0\\n\\n    for op in operations:\\n...   \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...   \n",
       "\n",
       "                                                test              entry_point  \\\n",
       "0  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...       has_close_elements   \n",
       "1  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...    separate_paren_groups   \n",
       "2  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...          truncate_number   \n",
       "3  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...               below_zero   \n",
       "4  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...  mean_absolute_deviation   \n",
       "\n",
       "                                     prompt_original  \\\n",
       "0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                          prompt_low  \\\n",
       "0  from typing import List\\n\\ndef has_close_eleme...   \n",
       "1  from typing import List\\n\\ndef separate_paren_...   \n",
       "2  def truncate_number(arg0: float) -> float:\\n  ...   \n",
       "3  from typing import List\\n\\ndef below_zero(arg0...   \n",
       "4  from typing import List\\n\\ndef mean_absolute_d...   \n",
       "\n",
       "                                         prompt_high  \n",
       "0  from typing import List\\n\\ndef has_close_eleme...  \n",
       "1  from typing import List\\n\\ndef separate_paren_...  \n",
       "2  def truncate_number(arg0: float) -> float:\\n  ...  \n",
       "3  from typing import List\\n\\ndef below_zero(arg0...  \n",
       "4  from typing import List\\n\\ndef mean_absolute_d...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_20_obf = load_from_disk(\"./data/openai_humaneval/humaneval_test_20_with_obf\")\n",
    "df = ds_20_obf.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8559c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder/.conda/envs/ml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/codet5p-2b:\n",
      "- modeling_codet5p.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"Salesforce/codet5p-2b\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint,\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5799d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variant = \"prompt_original\"\n",
    "prompt = df.loc[0, variant]\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31192e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_code = \"def fit_linear_regression(X, y):\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1a38318",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_2 = \"prompt_low\"\n",
    "prompt = df.loc[0, variant_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551dce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_3 = \"prompt_high\"\n",
    "prompt = df.loc[0, variant_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9643cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "def has_close_elements(arg0: List[float], arg1: float) -> bool:\n",
      "        \"\"\"\n",
      "    Check if in given list of arg0, are any two arg0 closer to each other than given arg1.\n",
      "    \"\"\"\n",
      "        for i in range(len(arg0)):\n",
      "            for j in range(i+1, len(arg0)):\n",
      "                if abs(arg0[i] - arg0[j]) < arg1:\n",
      "                    return True\n",
      "        return False\n",
      "\n",
      "def has_close_elements_2(arg0: List[float], arg1: float) -> bool:\n",
      "    \"\"\"\n",
      "    Check if in given list of arg0, are any two arg0 closer to each other than given arg1.\n",
      "    \"\"\"\n",
      "        for i in range(len(arg0)):\n",
      "            for j in range(i+1, len(arg0)):\n",
      "                if abs(arg0[i] - arg0[j]) < arg1:\n",
      "                    return True\n",
      "        return False\n",
      "\n",
      "def has_close_elements_3(arg0: List[float], arg1\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "encoding['decoder_input_ids'] = encoding['input_ids'].clone()\n",
    "outputs = model.generate(**encoding, max_length=256)\n",
    "answear = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cd6994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_clean_function_body(generated: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract executable function body only:\n",
    "    - removes repeated def\n",
    "    - removes docstrings\n",
    "    - stops at indentation break\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove regenerated def if present\n",
    "    def_match = re.search(r\"def\\s+\\w+\\s*\\(.*?\\):\", generated)\n",
    "    if def_match:\n",
    "        generated = generated[def_match.end():]\n",
    "\n",
    "    lines = generated.splitlines()\n",
    "    body_lines = []\n",
    "    started = False\n",
    "    in_docstring = False\n",
    "\n",
    "    for line in lines:\n",
    "        if not started:\n",
    "            if line.strip() == \"\":\n",
    "                continue\n",
    "            if line.startswith(\"    \") or line.startswith(\"\\t\"):\n",
    "                started = True\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        stripped = line.lstrip()\n",
    "\n",
    "        # Docstring toggle\n",
    "        if stripped.startswith('\"\"\"') or stripped.startswith(\"'''\"):\n",
    "            in_docstring = not in_docstring\n",
    "            continue\n",
    "\n",
    "        if in_docstring:\n",
    "            continue\n",
    "\n",
    "        # Stop if indentation breaks\n",
    "        if not (line.startswith(\"    \") or line.startswith(\"\\t\") or line.strip() == \"\"):\n",
    "            break\n",
    "\n",
    "        body_lines.append(line)\n",
    "\n",
    "    body = \"\\n\".join(body_lines).rstrip()\n",
    "    return body + \"\\n\" if body else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e27ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codet5_generate_raw(prompt: str, model, tokenizer, device, max_length: int = 256) -> str:\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    encoding[\"decoder_input_ids\"] = encoding[\"input_ids\"].clone()\n",
    "    outputs = model.generate(**encoding, max_length=max_length)\n",
    "    answer = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9441f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== RAW GENERATION =====\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for i in range(len(numbers) - 1):\n",
      "        if numbers[i + 1] - numbers[i] < threshold:\n",
      "            return True\n",
      "    return False\n",
      "    \n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "===== CLEAN BODY =====\n",
      "    for i in range(len(numbers) - 1):\n",
      "        if numbers[i + 1] - numbers[i] < threshold:\n",
      "            return True\n",
      "    return False\n",
      "\n",
      "\n",
      "===== FULL FUNCTION =====\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for i in range(len(numbers) - 1):\n",
      "        if numbers[i + 1] - numbers[i] < threshold:\n",
      "            return True\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_idx = 0\n",
    "prompt = df.loc[row_idx, \"prompt_original\"]\n",
    "\n",
    "raw = codet5_generate_raw(prompt, model, tokenizer, device)\n",
    "body = extract_clean_function_body(raw)\n",
    "\n",
    "print(\"===== RAW GENERATION =====\")\n",
    "print(raw)\n",
    "\n",
    "print(\"\\n===== CLEAN BODY =====\")\n",
    "print(body)\n",
    "\n",
    "print(\"\\n===== FULL FUNCTION =====\")\n",
    "print(prompt + body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d5057f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "df[\"codet5_solution_original\"] = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    prompt = df.loc[i, \"prompt_original\"]\n",
    "    raw = codet5_generate_raw(prompt, model, tokenizer, device)\n",
    "    body = extract_clean_function_body(raw)\n",
    "    df.loc[i, \"codet5_solution_original\"] = body\n",
    "\n",
    "print(\"Generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37427423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "df[\"codet5_solution_low\"] = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    prompt = df.loc[i, \"prompt_low\"]\n",
    "    raw = codet5_generate_raw(prompt, model, tokenizer, device)\n",
    "    body = extract_clean_function_body(raw)\n",
    "    df.loc[i, \"codet5_solution_low\"] = body\n",
    "\n",
    "print(\"Generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e58bbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "df[\"codet5_solution_high\"] = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    prompt = df.loc[i, \"prompt_high\"]\n",
    "    raw = codet5_generate_raw(prompt, model, tokenizer, device)\n",
    "    body = extract_clean_function_body(raw)\n",
    "    df.loc[i, \"codet5_solution_high\"] = body\n",
    "\n",
    "print(\"Generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b11f12a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "      <th>test</th>\n",
       "      <th>entry_point</th>\n",
       "      <th>prompt_original</th>\n",
       "      <th>prompt_low</th>\n",
       "      <th>prompt_high</th>\n",
       "      <th>codet5_solution_original</th>\n",
       "      <th>codet5_solution_low</th>\n",
       "      <th>codet5_solution_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>has_close_elements</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>for i in range(len(numbers) - 1):\\n       ...</td>\n",
       "      <td>for i in range(len(arg0)):\\n        for j ...</td>\n",
       "      <td>for i in range(len(arg0)):\\n          ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>separate_paren_groups</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>paren_string = paren_string.replace(' ', '...</td>\n",
       "      <td>paren_groups = []\\n    paren_stack = []\\n ...</td>\n",
       "      <td>paren_stack = []\\n        paren_list =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>truncate_number</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>if number == 0:\\n        return 0\\n    if ...</td>\n",
       "      <td>return arg0 - int(arg0)\\n</td>\n",
       "      <td>return arg0\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>below_zero</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>for operation in operations:\\n        if o...</td>\n",
       "      <td>if arg0[0] &lt; 0:\\n        return True\\n    ...</td>\n",
       "      <td>if arg0[0] &lt; 0:\\n            return Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>mean_absolute_deviation</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>arg0_mean = sum(arg0) / len(arg0)\\n    ret...</td>\n",
       "      <td>return sum(abs(x - arg0[0]) for x in a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id                                             prompt  \\\n",
       "0  HumanEval/0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  HumanEval/1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  HumanEval/2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  HumanEval/3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  HumanEval/4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                  canonical_solution  \\\n",
       "0      for idx, elem in enumerate(numbers):\\n    ...   \n",
       "1      result = []\\n    current_string = []\\n    ...   \n",
       "2                              return number % 1.0\\n   \n",
       "3      balance = 0\\n\\n    for op in operations:\\n...   \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...   \n",
       "\n",
       "                                                test              entry_point  \\\n",
       "0  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...       has_close_elements   \n",
       "1  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...    separate_paren_groups   \n",
       "2  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...          truncate_number   \n",
       "3  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...               below_zero   \n",
       "4  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...  mean_absolute_deviation   \n",
       "\n",
       "                                     prompt_original  \\\n",
       "0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                          prompt_low  \\\n",
       "0  from typing import List\\n\\ndef has_close_eleme...   \n",
       "1  from typing import List\\n\\ndef separate_paren_...   \n",
       "2  def truncate_number(arg0: float) -> float:\\n  ...   \n",
       "3  from typing import List\\n\\ndef below_zero(arg0...   \n",
       "4  from typing import List\\n\\ndef mean_absolute_d...   \n",
       "\n",
       "                                         prompt_high  \\\n",
       "0  from typing import List\\n\\ndef has_close_eleme...   \n",
       "1  from typing import List\\n\\ndef separate_paren_...   \n",
       "2  def truncate_number(arg0: float) -> float:\\n  ...   \n",
       "3  from typing import List\\n\\ndef below_zero(arg0...   \n",
       "4  from typing import List\\n\\ndef mean_absolute_d...   \n",
       "\n",
       "                            codet5_solution_original  \\\n",
       "0      for i in range(len(numbers) - 1):\\n       ...   \n",
       "1      paren_string = paren_string.replace(' ', '...   \n",
       "2      if number == 0:\\n        return 0\\n    if ...   \n",
       "3      for operation in operations:\\n        if o...   \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...   \n",
       "\n",
       "                                 codet5_solution_low  \\\n",
       "0      for i in range(len(arg0)):\\n        for j ...   \n",
       "1      paren_groups = []\\n    paren_stack = []\\n ...   \n",
       "2                          return arg0 - int(arg0)\\n   \n",
       "3      if arg0[0] < 0:\\n        return True\\n    ...   \n",
       "4      arg0_mean = sum(arg0) / len(arg0)\\n    ret...   \n",
       "\n",
       "                                codet5_solution_high  \n",
       "0          for i in range(len(arg0)):\\n          ...  \n",
       "1          paren_stack = []\\n        paren_list =...  \n",
       "2                                      return arg0\\n  \n",
       "3          if arg0[0] < 0:\\n            return Tr...  \n",
       "4          return sum(abs(x - arg0[0]) for x in a...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81c871ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean = sum(numbers) / len(numbers)\n",
      "    return sum(abs(x - mean) for x in numbers) / len(numbers)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[4][\"canonical_solution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39e753a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean = sum(numbers) / len(numbers)\n",
      "    return sum(abs(x - mean) for x in numbers) / len(numbers)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[4][\"codet5_solution_original\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ea76a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    arg0_mean = sum(arg0) / len(arg0)\n",
      "    return sum([abs(x - arg0_mean) for x in arg0]) / len(arg0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[4][\"codet5_solution_low\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8f6af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        return sum(abs(x - arg0[0]) for x in arg0) / len(arg0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[4][\"codet5_solution_high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f322dd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/openai_humaneval/humaneval_test_20_with_codet5_original.jsonl\n"
     ]
    }
   ],
   "source": [
    "out_path = \"./data/openai_humaneval/humaneval_test_20_with_codet5_original.jsonl\"\n",
    "\n",
    "df.to_json(out_path, orient=\"records\", lines=True)\n",
    "print(\"Saved to:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fbf1624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1b137",
   "metadata": {},
   "source": [
    "Let us try couple of more coder models for further ananlysis in this block to see how different trained models will behave on the codes in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890c0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ba2455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56867c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./data/openai_humaneval/humaneval_test_20_with_codet5_original.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a8eedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = \"prompt_original\"\n",
    "prompt = df.loc[0, variant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bea1fad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='linear': {'type'}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\", trust_remote_code=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b7e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    for i in range(len(numbers)):\n",
      "        for j in range(i + 1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    import doctest\n",
      "    doctest.testmod()\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_length=256)\n",
    "answear = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(answear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d426e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    for i in range(len(numbers)):\n",
      "        for j in range(i + 1, len(numbers)):\n",
      "            if abs(numbers[i] - numbers[j]) < threshold:\n",
      "                return True\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "body = extract_clean_function_body(answear)\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32847ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_generate_raw(prompt: str, model, tokenizer, device, max_length: int = 256) -> str:\n",
    "    encoding = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**encoding, max_length=max_length)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd0caad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== RAW GENERATION =====\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(arg0: List[float], arg1: float) -> bool:\n",
      "    \"\"\" Check if in given list of arg0, are any two arg0 closer to each other than\n",
      "    given arg1.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    return False\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "===== CLEAN BODY =====\n",
      "    return False\n",
      "\n",
      "\n",
      "===== FULL FUNCTION =====\n",
      "from typing import List\n",
      "\n",
      "def has_close_elements(arg0: List[float], arg1: float) -> bool:\n",
      "    \"\"\" Check if in given list of arg0, are any two arg0 closer to each other than\n",
      "    given arg1.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row_idx = 0\n",
    "prompt = df.loc[row_idx, \"prompt_low\"]\n",
    "\n",
    "raw = deepseek_generate_raw(prompt, model, tokenizer, device)\n",
    "body = extract_clean_function_body(raw)\n",
    "\n",
    "print(\"===== RAW GENERATION =====\")\n",
    "print(raw)\n",
    "\n",
    "print(\"\\n===== CLEAN BODY =====\")\n",
    "print(body)\n",
    "\n",
    "print(\"\\n===== FULL FUNCTION =====\")\n",
    "print(prompt + body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de7526ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "df[\"deepseek_solution_original\"] = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    prompt = df.loc[i, \"prompt_original\"]\n",
    "    raw = deepseek_generate_raw(prompt, model, tokenizer, device)\n",
    "    body = extract_clean_function_body(raw)\n",
    "    df.loc[i, \"deepseek_solution_original\"] = body\n",
    "\n",
    "print(\"Generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eea1bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "df[\"deepseek_solution_low\"] = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    prompt = df.loc[i, \"prompt_low\"]\n",
    "    raw = deepseek_generate_raw(prompt, model, tokenizer, device)\n",
    "    body = extract_clean_function_body(raw)\n",
    "    df.loc[i, \"deepseek_solution_low\"] = body\n",
    "\n",
    "print(\"Generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f84b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:32014 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "df[\"deepseek_solution_high\"] = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "    prompt = df.loc[i, \"prompt_high\"]\n",
    "    raw = deepseek_generate_raw(prompt, model, tokenizer, device)\n",
    "    body = extract_clean_function_body(raw)\n",
    "    df.loc[i, \"deepseek_solution_high\"] = body\n",
    "\n",
    "print(\"Generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0c7c663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>canonical_solution</th>\n",
       "      <th>test</th>\n",
       "      <th>entry_point</th>\n",
       "      <th>prompt_original</th>\n",
       "      <th>prompt_low</th>\n",
       "      <th>prompt_high</th>\n",
       "      <th>codet5_solution_original</th>\n",
       "      <th>codet5_solution_low</th>\n",
       "      <th>codet5_solution_high</th>\n",
       "      <th>deepseek_solution_original</th>\n",
       "      <th>deepseek_solution_low</th>\n",
       "      <th>deepseek_solution_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HumanEval/0</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>for idx, elem in enumerate(numbers):\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>has_close_elements</td>\n",
       "      <td>from typing import List\\n\\n\\ndef has_close_ele...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>from typing import List\\n\\ndef has_close_eleme...</td>\n",
       "      <td>for i in range(len(numbers) - 1):\\n       ...</td>\n",
       "      <td>for i in range(len(arg0)):\\n        for j ...</td>\n",
       "      <td>for i in range(len(arg0)):\\n          ...</td>\n",
       "      <td>for i in range(len(numbers)):\\n        for...</td>\n",
       "      <td>return False\\n</td>\n",
       "      <td>return False\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HumanEval/1</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>result = []\\n    current_string = []\\n    ...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>separate_paren_groups</td>\n",
       "      <td>from typing import List\\n\\n\\ndef separate_pare...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>from typing import List\\n\\ndef separate_paren_...</td>\n",
       "      <td>paren_string = paren_string.replace(' ', '...</td>\n",
       "      <td>paren_groups = []\\n    paren_stack = []\\n ...</td>\n",
       "      <td>paren_stack = []\\n        paren_list =...</td>\n",
       "      <td>paren_stack = []\\n    paren_list = []\\n   ...</td>\n",
       "      <td># TODO: Write your code here\\n    pass\\n</td>\n",
       "      <td>assert separate_paren_groups(\"(a)\") == [\"a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HumanEval/2</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>return number % 1.0\\n</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>truncate_number</td>\n",
       "      <td>\\n\\ndef truncate_number(number: float) -&gt; floa...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>def truncate_number(arg0: float) -&gt; float:\\n  ...</td>\n",
       "      <td>if number == 0:\\n        return 0\\n    if ...</td>\n",
       "      <td>return arg0 - int(arg0)\\n</td>\n",
       "      <td>return arg0\\n</td>\n",
       "      <td>return number - int(number)\\n</td>\n",
       "      <td>return arg0 - int(arg0)\\n</td>\n",
       "      <td>return trunc(arg0)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HumanEval/3</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>balance = 0\\n\\n    for op in operations:\\n...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>below_zero</td>\n",
       "      <td>from typing import List\\n\\n\\ndef below_zero(op...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>from typing import List\\n\\ndef below_zero(arg0...</td>\n",
       "      <td>for operation in operations:\\n        if o...</td>\n",
       "      <td>if arg0[0] &lt; 0:\\n        return True\\n    ...</td>\n",
       "      <td>if arg0[0] &lt; 0:\\n            return Tr...</td>\n",
       "      <td>balance = 0\\n    for operation in operatio...</td>\n",
       "      <td>return False\\n</td>\n",
       "      <td>if sum(arg0) &lt; 0:\\n        return True\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HumanEval/4</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>\\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...</td>\n",
       "      <td>mean_absolute_deviation</td>\n",
       "      <td>from typing import List\\n\\n\\ndef mean_absolute...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>from typing import List\\n\\ndef mean_absolute_d...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>arg0_mean = sum(arg0) / len(arg0)\\n    ret...</td>\n",
       "      <td>return sum(abs(x - arg0[0]) for x in a...</td>\n",
       "      <td>mean = sum(numbers) / len(numbers)\\n    re...</td>\n",
       "      <td>return 0.0\\n</td>\n",
       "      <td>return 0.0\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task_id                                             prompt  \\\n",
       "0  HumanEval/0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  HumanEval/1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  HumanEval/2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  HumanEval/3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  HumanEval/4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                  canonical_solution  \\\n",
       "0      for idx, elem in enumerate(numbers):\\n    ...   \n",
       "1      result = []\\n    current_string = []\\n    ...   \n",
       "2                              return number % 1.0\\n   \n",
       "3      balance = 0\\n\\n    for op in operations:\\n...   \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...   \n",
       "\n",
       "                                                test              entry_point  \\\n",
       "0  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...       has_close_elements   \n",
       "1  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...    separate_paren_groups   \n",
       "2  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...          truncate_number   \n",
       "3  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...               below_zero   \n",
       "4  \\n\\nMETADATA = {\\n    'author': 'jt',\\n    'da...  mean_absolute_deviation   \n",
       "\n",
       "                                     prompt_original  \\\n",
       "0  from typing import List\\n\\n\\ndef has_close_ele...   \n",
       "1  from typing import List\\n\\n\\ndef separate_pare...   \n",
       "2  \\n\\ndef truncate_number(number: float) -> floa...   \n",
       "3  from typing import List\\n\\n\\ndef below_zero(op...   \n",
       "4  from typing import List\\n\\n\\ndef mean_absolute...   \n",
       "\n",
       "                                          prompt_low  \\\n",
       "0  from typing import List\\n\\ndef has_close_eleme...   \n",
       "1  from typing import List\\n\\ndef separate_paren_...   \n",
       "2  def truncate_number(arg0: float) -> float:\\n  ...   \n",
       "3  from typing import List\\n\\ndef below_zero(arg0...   \n",
       "4  from typing import List\\n\\ndef mean_absolute_d...   \n",
       "\n",
       "                                         prompt_high  \\\n",
       "0  from typing import List\\n\\ndef has_close_eleme...   \n",
       "1  from typing import List\\n\\ndef separate_paren_...   \n",
       "2  def truncate_number(arg0: float) -> float:\\n  ...   \n",
       "3  from typing import List\\n\\ndef below_zero(arg0...   \n",
       "4  from typing import List\\n\\ndef mean_absolute_d...   \n",
       "\n",
       "                            codet5_solution_original  \\\n",
       "0      for i in range(len(numbers) - 1):\\n       ...   \n",
       "1      paren_string = paren_string.replace(' ', '...   \n",
       "2      if number == 0:\\n        return 0\\n    if ...   \n",
       "3      for operation in operations:\\n        if o...   \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...   \n",
       "\n",
       "                                 codet5_solution_low  \\\n",
       "0      for i in range(len(arg0)):\\n        for j ...   \n",
       "1      paren_groups = []\\n    paren_stack = []\\n ...   \n",
       "2                          return arg0 - int(arg0)\\n   \n",
       "3      if arg0[0] < 0:\\n        return True\\n    ...   \n",
       "4      arg0_mean = sum(arg0) / len(arg0)\\n    ret...   \n",
       "\n",
       "                                codet5_solution_high  \\\n",
       "0          for i in range(len(arg0)):\\n          ...   \n",
       "1          paren_stack = []\\n        paren_list =...   \n",
       "2                                      return arg0\\n   \n",
       "3          if arg0[0] < 0:\\n            return Tr...   \n",
       "4          return sum(abs(x - arg0[0]) for x in a...   \n",
       "\n",
       "                          deepseek_solution_original  \\\n",
       "0      for i in range(len(numbers)):\\n        for...   \n",
       "1      paren_stack = []\\n    paren_list = []\\n   ...   \n",
       "2                      return number - int(number)\\n   \n",
       "3      balance = 0\\n    for operation in operatio...   \n",
       "4      mean = sum(numbers) / len(numbers)\\n    re...   \n",
       "\n",
       "                          deepseek_solution_low  \\\n",
       "0                                return False\\n   \n",
       "1      # TODO: Write your code here\\n    pass\\n   \n",
       "2                     return arg0 - int(arg0)\\n   \n",
       "3                                return False\\n   \n",
       "4                                  return 0.0\\n   \n",
       "\n",
       "                              deepseek_solution_high  \n",
       "0                                     return False\\n  \n",
       "1      assert separate_paren_groups(\"(a)\") == [\"a...  \n",
       "2                               return trunc(arg0)\\n  \n",
       "3      if sum(arg0) < 0:\\n        return True\\n  ...  \n",
       "4                                       return 0.0\\n  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d600a999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ./data/openai_humaneval/humaneval_completed.jsonl\n"
     ]
    }
   ],
   "source": [
    "out_path = \"./data/openai_humaneval/humaneval_completed.jsonl\"\n",
    "\n",
    "df.to_json(out_path, orient=\"records\", lines=True)\n",
    "print(\"Saved to:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
