# Privacy–Utility Trade-off in Code Completion

## Task Description

The goal of this project is to study the **privacy–utility trade-off** in code completion models under prompt obfuscation, using a subset of the *openai_humaneval* benchmark.

For each task, multiple versions of the prompt are constructed:
- the original prompt,
- a low-obfuscation variant (e.g., variable renaming),
- a high-obfuscation variant (e.g., placeholder identifiers and comment removal).

Two code completion models are evaluated on these prompts, and their generated solutions are compared to canonical HumanEval solutions using quantitative metrics.

---

## Dataset

All generated prompts and model completions are stored directly in the repository as a dataset file.  
This dataset includes:
- original, low-obfuscated, and high-obfuscated prompts,
- completions generated by CodeT5+ and DeepSeek-Coder,
- canonical HumanEval solutions.

The dataset is intended to make the experiment fully reproducible without requiring re-running model inference.

---

## Analysis

The notebook `analysis.ipynb` contains the **final evaluation and analysis** of the experiment.  
It computes:
- utility scores (ROUGE-L),
- privacy scores (normalized Levenshtein distance),
- privacy–utility plots and summary statistics.

This notebook can be run end-to-end using the provided dataset, just cerrect the path.
The results are pretty expected, for this type of experiments.

---

## Environment Setup

If you want to create a Python environment from scratch, you can use either `venv` or Conda.

### Using `venv`
```bash
python -m venv venv
source venv/bin/activate      # Linux / macOS
# venv\Scripts\activate       # Windows

pip install -r requirements.txt

### Using conda

conda create -n code-privacy python=3.10
conda activate code-privacy
pip install -r requirements.txt